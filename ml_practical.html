<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.353">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
<meta name="author" content="Sean Davis">
<meta name="dcterms.date" content="2023-07-09">
<meta name="description" content="A collection of chapters more than a book, but….">
<title>The RBioc Book - 14&nbsp; Machine Learning</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>

<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./geoquery.html" rel="next">
<link href="./kmeans.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light"><script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script><style>html{ scroll-behavior: smooth; }</style>
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>
</head>
<body class="nav-sidebar floating slimcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top"><nav class="quarto-secondary-nav"><div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./norm.html">Statistics and Machine Learning</a></li><li class="breadcrumb-item"><a href="./ml_practical.html"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Machine Learning</span></a></li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav></header><!-- content --><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation floating overflow-auto"><div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">The RBioc Book</a> 
        <div class="sidebar-tools-main tools-wide">
    <a href="https://github.com/seandavi/RBiocBook" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
    <div class="dropdown">
      <a href="" title="Download" id="quarto-navigation-tool-dropdown-0" class="quarto-navigation-tool dropdown-toggle px-1" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download"><i class="bi bi-download"></i></a>
      <ul class="dropdown-menu" aria-labelledby="quarto-navigation-tool-dropdown-0">
<li>
            <a class="dropdown-item sidebar-tools-main-item" href="./The-RBioc-Book.pdf">
              <i class="bi bi-bi-file-pdf pe-1"></i>
            Download PDF
            </a>
          </li>
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="./The-RBioc-Book.epub">
              <i class="bi bi-bi-journal pe-1"></i>
            Download ePub
            </a>
          </li>
      </ul>
</div>
    <div class="dropdown">
      <a href="" title="Share" id="quarto-navigation-tool-dropdown-1" class="quarto-navigation-tool dropdown-toggle px-1" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Share"><i class="bi bi-share"></i></a>
      <ul class="dropdown-menu" aria-labelledby="quarto-navigation-tool-dropdown-1">
<li>
            <a class="dropdown-item sidebar-tools-main-item" href="https://twitter.com/intent/tweet?url=%7Curl%7C">
              <i class="bi bi-bi-twitter pe-1"></i>
            Twitter
            </a>
          </li>
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="https://www.facebook.com/sharer/sharer.php?u=%7Curl%7C">
              <i class="bi bi-bi-facebook pe-1"></i>
            Facebook
            </a>
          </li>
      </ul>
</div>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
 <span class="menu-text">Introduction</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introducing R and RStudio</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./r_intro_mechanics.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">R mechanics</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./r_basics.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Up and Running with R</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./packages_and_dice.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Packages and more dice</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./data_structures_overview.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Overview of R Data Structures</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./vectors.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Vectors</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./matrices.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Matrices</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./dataframes_intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Data Frames</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./factors.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Factors</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./eda_overview.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Exploratory data analysis</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./dplyr_intro_msleep.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Introduction to dplyr: mammal sleep dataset</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./eda_and_univariate_brfss.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Case Study: Behavioral Risk Factor Surveillance System</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true">
 <span class="menu-text">Statistics and Machine Learning</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./norm.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Working with distribution functions</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./t-stats-and-tests.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">The t-statistic and t-distribution</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./kmeans.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">K-means clustering</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ml_practical.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Machine Learning</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="true">
 <span class="menu-text">Bioconductor</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./geoquery.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Accessing and working with public omics data</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./bioc-summarizedexperiment.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Introduction to <code>SummarizedExperiment</code></span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./eda_with_pca.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">EDA with PCA</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ranges_and_signals.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Genomic ranges and features</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./atac.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">ATAC-Seq with Bioconductor</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" aria-expanded="true">
 <span class="menu-text">Appendices</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./appendix.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">A</span>&nbsp; <span class="chapter-title">Appendix</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./additional_resources.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">B</span>&nbsp; <span class="chapter-title">Additional resources</span></span></a>
  </div>
</li>
      </ul>
</li>
    </ul>
</div>
</nav><div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active"><h2 id="toc-title">Table of contents</h2>
   
  <ul>
<li><a href="#what-is-machine-learning" id="toc-what-is-machine-learning" class="nav-link active" data-scroll-target="#what-is-machine-learning"><span class="header-section-number">14.1</span> What is Machine Learning?</a></li>
  <li>
<a href="#classes-of-machine-learning" id="toc-classes-of-machine-learning" class="nav-link" data-scroll-target="#classes-of-machine-learning"><span class="header-section-number">14.2</span> Classes of Machine Learning</a>
  <ul class="collapse">
<li><a href="#supervised-learning" id="toc-supervised-learning" class="nav-link" data-scroll-target="#supervised-learning"><span class="header-section-number">14.2.1</span> Supervised learning</a></li>
  <li><a href="#unsupervised-learning" id="toc-unsupervised-learning" class="nav-link" data-scroll-target="#unsupervised-learning"><span class="header-section-number">14.2.2</span> Unsupervised learning</a></li>
  <li><a href="#other-types-of-machine-learning" id="toc-other-types-of-machine-learning" class="nav-link" data-scroll-target="#other-types-of-machine-learning"><span class="header-section-number">14.2.3</span> Other types of machine learning</a></li>
  </ul>
</li>
  <li>
<a href="#specific-methods" id="toc-specific-methods" class="nav-link" data-scroll-target="#specific-methods"><span class="header-section-number">14.3</span> Specific methods</a>
  <ul class="collapse">
<li><a href="#linear-regression" id="toc-linear-regression" class="nav-link" data-scroll-target="#linear-regression"><span class="header-section-number">14.3.1</span> Linear regression</a></li>
  <li><a href="#k-nearest-neighbor" id="toc-k-nearest-neighbor" class="nav-link" data-scroll-target="#k-nearest-neighbor"><span class="header-section-number">14.3.2</span> K-nearest Neighbor</a></li>
  <li><a href="#classification-and-regression-trees-cart" id="toc-classification-and-regression-trees-cart" class="nav-link" data-scroll-target="#classification-and-regression-trees-cart"><span class="header-section-number">14.3.3</span> Classification and Regression Trees (CART)</a></li>
  <li><a href="#randomforest" id="toc-randomforest" class="nav-link" data-scroll-target="#randomforest"><span class="header-section-number">14.3.4</span> RandomForest</a></li>
  </ul>
</li>
  <li>
<a href="#practical-machine-learning-with-r-and-mlr3" id="toc-practical-machine-learning-with-r-and-mlr3" class="nav-link" data-scroll-target="#practical-machine-learning-with-r-and-mlr3"><span class="header-section-number">14.4</span> Practical Machine Learning with R and mlr3</a>
  <ul class="collapse">
<li><a href="#key-features-of-mlr3" id="toc-key-features-of-mlr3" class="nav-link" data-scroll-target="#key-features-of-mlr3"><span class="header-section-number">14.4.1</span> Key features of mlr3</a></li>
  </ul>
</li>
  </ul><div class="toc-actions"><div><i class="bi bi-github"></i></div><div class="action-links"><p><a href="https://github.com/seandavi/RBiocBook/edit/main/ml_practical.qmd" class="toc-action">Edit this page</a></p></div></div></nav>
    </div>
<!-- main -->
<main class="content page-columns page-full" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block default"><div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title">
<span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Machine Learning</span>
</h1><button type="button" class="btn code-tools-button dropdown-toggle" id="quarto-code-tools-menu" data-bs-toggle="dropdown" aria-expanded="false"><i class="bi"></i> Code</button><ul class="dropdown-menu dropdown-menu-end" aria-labelelledby="quarto-code-tools-menu"><li><a id="quarto-show-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Show All Code</a></li><li><a id="quarto-hide-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Hide All Code</a></li><li><hr class="dropdown-divider"></li><li><a id="quarto-view-source" class="dropdown-item" href="javascript:void(0)" role="button" data-quarto-source-url="https://github.com/seandavi/RBiocBook/blob/main/ml_practical.qmd">View Source</a></li></ul></div></div>
</div>


<div class="quarto-title-meta-author">
  <div class="quarto-title-meta-heading">Author</div>
  <div class="quarto-title-meta-heading">Affiliation</div>
  
    <div class="quarto-title-meta-contents">
    <p class="author"><a href="https://seandavi.github.io/">Sean Davis</a> </p>
  </div>
    <div class="quarto-title-meta-contents">
        <p class="affiliation">
            <a href="https://medschool.cuanschutz.edu/">
            University of Colorado<br>Anschutz School of Medicine
            </a>
          </p>
      </div>
    </div>

<div class="quarto-title-meta">

      
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">July 9, 2023</p>
    </div>
  </div>
  
    
  </div>
  

</header><section id="what-is-machine-learning" class="level2" data-number="14.1"><h2 data-number="14.1" class="anchored" data-anchor-id="what-is-machine-learning">
<span class="header-section-number">14.1</span> What is Machine Learning?</h2>
<p>Machine learning is a subfield of artificial intelligence that focuses on the development of algorithms and models that enable computers to learn and make decisions or predictions without explicit programming. It has emerged as a powerful tool for solving complex problems across various industries, including healthcare, finance, marketing, and natural language processing. This chapter provides an overview of machine learning, its types, key concepts, applications, and challenges.</p>
<p>Machine learning in biology is a really broad topic. <span class="citation" data-cites="greener_guide_2022">Greener et al. (<a href="references.html#ref-greener_guide_2022" role="doc-biblioref">2022</a>)</span> present a nice overview of the different types of machine learning methods that are used in biology. <span class="citation" data-cites="libbrecht_machine_2015">Libbrecht and Noble (<a href="references.html#ref-libbrecht_machine_2015" role="doc-biblioref">2015</a>)</span> also present an early review of machine learning in genetics and genomics.</p>
</section><section id="classes-of-machine-learning" class="level2 page-columns page-full" data-number="14.2"><h2 data-number="14.2" class="anchored" data-anchor-id="classes-of-machine-learning">
<span class="header-section-number">14.2</span> Classes of Machine Learning</h2>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode tikz code-with-copy"><code class="sourceCode latex"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">\usetikzlibrary</span>{fit, graphs, matrix, positioning}</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="kw">\begin</span>{<span class="ex">tikzpicture</span>}[node distance=2cm]</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="fu">\graph</span> [grow right sep, branch down=1cm, simple, nodes={draw, rectangle}] {</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>  Data[as=data <span class="ss">$D$</span>] -&gt; {dtrain[as=<span class="ss">$D_{train}$</span>], dtest[as=<span class="ss">$D_{test}$</span>]};</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>  dtrain -&gt; Learner;</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>  dtest -&gt; Model;</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>  Learner -&gt; Model;</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>  Model -&gt; Prediction;</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>  dtest -&gt; Measure;</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>  Prediction -&gt; Measure;</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>  Measure -&gt; Performance;</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>};</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="kw">\end</span>{<span class="ex">tikzpicture</span>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="ml_practical_files/figure-html/unnamed-chunk-1-1.png" class="img-fluid" width="300"></p>
</div>
</div>
<section id="supervised-learning" class="level3" data-number="14.2.1"><h3 data-number="14.2.1" class="anchored" data-anchor-id="supervised-learning">
<span class="header-section-number">14.2.1</span> Supervised learning</h3>
<p>Supervised learning is a type of machine learning where the model learns from labeled data, i.e., input-output pairs, to make predictions. It includes tasks like regression (predicting continuous values) and classification (predicting discrete classes or categories).</p>
</section><section id="unsupervised-learning" class="level3" data-number="14.2.2"><h3 data-number="14.2.2" class="anchored" data-anchor-id="unsupervised-learning">
<span class="header-section-number">14.2.2</span> Unsupervised learning</h3>
<p>Unsupervised learning involves learning from unlabeled data, where the model discovers patterns or structures within the data. Common unsupervised learning tasks include clustering (grouping similar data points), dimensionality reduction (reducing the number of features or variables), and anomaly detection (identifying unusual data points).</p>
</section><section id="other-types-of-machine-learning" class="level3 page-columns page-full" data-number="14.2.3"><h3 data-number="14.2.3" class="anchored" data-anchor-id="other-types-of-machine-learning">
<span class="header-section-number">14.2.3</span> Other types of machine learning</h3>
<p>Reinforcement learning is a type of machine learning where an agent learns to make decisions based on interactions with an environment. The agent receives feedback in the form of rewards or penalties and adjusts its actions to maximize the cumulative reward over time.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Terminology and Concepts
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><dl>
<dt>Data</dt>
<dd>
Data is the foundation of machine learning and can be structured (tabular) or unstructured (text, images, audio). It is usually divided into training, validation, and testing sets for model development and evaluation.
</dd>
</dl></li>
<li><dl>
<dt>Features</dt>
<dd>
Features are the variables or attributes used to describe the data points. Feature engineering and selection are crucial steps in machine learning to improve model performance and interpretability.
</dd>
</dl></li>
<li><dl>
<dt>Models and Algorithms</dt>
<dd>
Models are mathematical representations of the relationship between features and the target variable(s). Algorithms are the methods used to train models, such as linear regression, decision trees, and neaural networks.
</dd>
</dl></li>
<li><dl>
<dt>Hyperparameters and Tuning</dt>
<dd>
Hyperparameters are adjustable parameters that control the learning process of an algorithm. Tuning involves finding the optimal set of hyperparameters to improve model performance.
</dd>
</dl></li>
<li><dl>
<dt>Evaluation Metrics</dt>
<dd>
Evaluation metrics quantify the performance of a model, such as accuracy, precision, recall, F1-score (for classification), and mean squared error, R-squared (for regression).
</dd>
</dl></li>
</ul>
</div>
</div>
<ul>
<li>Supervised</li>
<li>Classification</li>
<li>Regression</li>
<li>Unsupervised</li>
<li>“Clustering”</li>
<li>Dimensionality reduction</li>
</ul>
<div class="cell page-columns page-full">
<details><summary>Code</summary><div class="sourceCode" id="cb2"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">123</span><span class="op">)</span></span>
<span><span class="va">sinsim</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">n</span>,<span class="va">sd</span><span class="op">=</span><span class="fl">0.1</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="va">x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="fl">0</span>,<span class="fl">1</span>,length.out<span class="op">=</span><span class="va">n</span><span class="op">)</span></span>
<span>  <span class="va">y</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/Trig.html">sin</a></span><span class="op">(</span><span class="fl">2</span><span class="op">*</span><span class="va">pi</span><span class="op">*</span><span class="va">x</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="va">n</span>,<span class="fl">0</span>,<span class="va">sd</span><span class="op">)</span></span>
<span>  <span class="kw"><a href="https://rdrr.io/r/base/function.html">return</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span>x<span class="op">=</span><span class="va">x</span>,y<span class="op">=</span><span class="va">y</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span><span class="va">dat</span> <span class="op">&lt;-</span> <span class="fu">sinsim</span><span class="op">(</span><span class="fl">100</span>,<span class="fl">0.25</span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://ggplot2.tidyverse.org">ggplot2</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://patchwork.data-imaginist.com">patchwork</a></span><span class="op">)</span></span>
<span><span class="va">p_base</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="va">dat</span>,<span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x<span class="op">=</span><span class="va">x</span>,y<span class="op">=</span><span class="va">y</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html">geom_point</a></span><span class="op">(</span>alpha<span class="op">=</span><span class="fl">0.7</span><span class="op">)</span> <span class="op">+</span></span>
<span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggtheme.html">theme_bw</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="va">p_lm</span> <span class="op">&lt;-</span> <span class="va">p_base</span> <span class="op">+</span> </span>
<span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_smooth.html">geom_smooth</a></span><span class="op">(</span>method<span class="op">=</span><span class="st">"lm"</span>, se<span class="op">=</span><span class="cn">FALSE</span>, alpha<span class="op">=</span><span class="fl">0.6</span>, formula <span class="op">=</span> <span class="va">y</span> <span class="op">~</span> <span class="va">x</span><span class="op">)</span> </span>
<span><span class="va">p_lmsin</span> <span class="op">&lt;-</span> <span class="va">p_base</span> <span class="op">+</span></span>
<span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_smooth.html">geom_smooth</a></span><span class="op">(</span>method<span class="op">=</span><span class="st">"lm"</span>,formula<span class="op">=</span><span class="va">y</span><span class="op">~</span><span class="fu"><a href="https://rdrr.io/r/base/Trig.html">sin</a></span><span class="op">(</span><span class="fl">2</span><span class="op">*</span><span class="va">pi</span><span class="op">*</span><span class="va">x</span><span class="op">)</span>, se<span class="op">=</span><span class="cn">FALSE</span>, alpha<span class="op">=</span><span class="fl">0.6</span><span class="op">)</span> </span>
<span><span class="va">p_loess_wide</span> <span class="op">&lt;-</span> <span class="va">p_base</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_smooth.html">geom_smooth</a></span><span class="op">(</span>method<span class="op">=</span><span class="st">"loess"</span>,span<span class="op">=</span><span class="fl">0.5</span>, se<span class="op">=</span><span class="cn">FALSE</span>, alpha<span class="op">=</span><span class="fl">0.6</span>, formula <span class="op">=</span> <span class="va">y</span> <span class="op">~</span> <span class="va">x</span><span class="op">)</span> </span>
<span><span class="va">p_loess_narrow</span> <span class="op">&lt;-</span> <span class="va">p_base</span> <span class="op">+</span> </span>
<span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_smooth.html">geom_smooth</a></span><span class="op">(</span>method<span class="op">=</span><span class="st">"loess"</span>,span<span class="op">=</span><span class="fl">0.1</span>, se<span class="op">=</span><span class="cn">FALSE</span>, alpha<span class="op">=</span><span class="fl">0.6</span>, formula <span class="op">=</span> <span class="va">y</span> <span class="op">~</span> <span class="va">x</span><span class="op">)</span> </span>
<span><span class="va">p_lm</span> <span class="op">+</span> <span class="va">p_lmsin</span> <span class="op">+</span> <span class="va">p_loess_wide</span> <span class="op">+</span> <span class="va">p_loess_narrow</span> <span class="op">+</span> <span class="fu"><a href="https://patchwork.data-imaginist.com/reference/plot_layout.html">plot_layout</a></span><span class="op">(</span>ncol<span class="op">=</span><span class="fl">2</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://patchwork.data-imaginist.com/reference/plot_annotation.html">plot_annotation</a></span><span class="op">(</span>tag_levels <span class="op">=</span> <span class="st">'A'</span><span class="op">)</span> <span class="op">&amp;</span> </span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/theme.html">theme</a></span><span class="op">(</span>plot.tag <span class="op">=</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/element.html">element_text</a></span><span class="op">(</span>size <span class="op">=</span> <span class="fl">8</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display page-columns page-full">
<div id="fig-fitting" class="quarto-figure quarto-figure-center anchored page-columns page-full">
<figure class="figure page-columns page-full"><p><img src="ml_practical_files/figure-html/fig-fitting-1.png" class="img-fluid figure-img" width="672"></p>
<figcaption class="figure-caption margin-caption">Figure&nbsp;14.1: Data simulated according to the function <span class="math inline">\(f(x) = sin(2 \pi x) + N(0,0.25)\)</span> fitted with four different models. A) A simple linear model demonstrates <em>underfitting</em>. B) A linear model with a sin function (<span class="math inline">\(y = sin(2 \pi x)\)</span>) and C) a loess model with a wide span (0.5) demonstrate <em>good fits</em>. D) A loess model with a narrow span (0.1) is a good example of <em>overfitting</em>.</figcaption></figure>
</div>
</div>
</div>
<div id="fig-sklearn" class="quarto-figure quarto-figure-center anchored page-columns page-full">
<figure class="figure page-columns page-full"><p><img src="https://1.bp.blogspot.com/-ME24ePzpzIM/UQLWTwurfXI/AAAAAAAAANw/W3EETIroA80/s1600/drop_shadows_background.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption margin-caption">Figure&nbsp;14.2: A simple view of machine learning according the sklearn.</figcaption></figure>
</div>
</section></section><section id="specific-methods" class="level2 page-columns page-full" data-number="14.3"><h2 data-number="14.3" class="anchored" data-anchor-id="specific-methods">
<span class="header-section-number">14.3</span> Specific methods</h2>
<section id="linear-regression" class="level3" data-number="14.3.1"><h3 data-number="14.3.1" class="anchored" data-anchor-id="linear-regression">
<span class="header-section-number">14.3.1</span> Linear regression</h3>
<p>In <a href="https://en.wikipedia.org/wiki/Statistics" title="Statistics">statistics</a>, <strong>linear regression</strong> is a <a href="https://en.wikipedia.org/wiki/Linearity" title="Linearity">linear</a> approach for modelling the relationship between a <a href="https://en.wikipedia.org/wiki/Scalar_(mathematics)" title="Scalar (mathematics)">scalar</a> response and one or more explanatory variables (also known as <a href="https://en.wikipedia.org/wiki/Dependent_and_independent_variables" title="Dependent and independent variables">dependent and independent variables</a>). The case of one explanatory variable is called <em><a href="https://en.wikipedia.org/wiki/Simple_linear_regression" title="Simple linear regression">simple linear regression</a></em>; for more than one, the process is called <strong>multiple linear regression</strong>. This term is distinct from <a href="https://en.wikipedia.org/wiki/Multivariate_linear_regression" title="Multivariate linear regression">multivariate linear regression</a>, where multiple <a href="https://en.wikipedia.org/wiki/Correlation_and_dependence" title="Correlation and dependence">correlated</a> dependent variables are predicted, rather than a single scalar variable.</p>
<p>In linear regression, the relationships are modeled using <a href="https://en.wikipedia.org/wiki/Linear_predictor_function" title="Linear predictor function">linear predictor functions</a> whose unknown model <a href="https://en.wikipedia.org/wiki/Parameters" title="Parameters">parameters</a> are <a href="https://en.wikipedia.org/wiki/Estimation_theory" title="Estimation theory">estimated</a> from the <a href="https://en.wikipedia.org/wiki/Data" title="Data">data</a>. Such models are called <a href="https://en.wikipedia.org/wiki/Linear_model" title="Linear model">linear models</a>. Most commonly, the <a href="https://en.wikipedia.org/wiki/Conditional_expectation" title="Conditional expectation">conditional mean</a> of the response given the values of the explanatory variables (or predictors) is assumed to be an <a href="https://en.wikipedia.org/wiki/Affine_transformation" title="Affine transformation">affine function</a> of those values; less commonly, the conditional <a href="https://en.wikipedia.org/wiki/Median" title="Median">median</a> or some other <a href="https://en.wikipedia.org/wiki/Quantile" title="Quantile">quantile</a> is used. Like all forms of <a href="https://en.wikipedia.org/wiki/Regression_analysis" title="Regression analysis">regression analysis</a>, linear regression focuses on the <a href="https://en.wikipedia.org/wiki/Conditional_probability_distribution" title="Conditional probability distribution">conditional probability distribution</a> of the response given the values of the predictors, rather than on the <a href="https://en.wikipedia.org/wiki/Joint_probability_distribution" title="Joint probability distribution">joint probability distribution</a> of all of these variables, which is the domain of <a href="https://en.wikipedia.org/wiki/Multivariate_analysis" title="Multivariate analysis">multivariate analysis</a>.</p>
<p>Linear regression was the first type of regression analysis to be studied rigorously, and to be used extensively in practical applications. This is because models which depend linearly on their unknown parameters are easier to fit than models which are non-linearly related to their parameters and because the statistical properties of the resulting estimators are easier to determine.</p>
</section><section id="k-nearest-neighbor" class="level3 page-columns page-full" data-number="14.3.2"><h3 data-number="14.3.2" class="anchored" data-anchor-id="k-nearest-neighbor">
<span class="header-section-number">14.3.2</span> K-nearest Neighbor</h3>
<div class="cell page-columns page-full">
<div class="cell-output-display page-columns page-full">
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full"><p><img src="https://www.kdnuggets.com/wp-content/uploads/rapidminer-knn-image1.jpg" class="img-fluid figure-img"></p>
<figcaption class="figure-caption margin-caption"><strong>Figure</strong>. The k-nearest neighbor algorithm can be used for regression or classification.</figcaption></figure>
</div>
</div>
</div>
<p>The <strong><em>k</em>-nearest neighbors algorithm</strong> (<strong><em>k</em>-NN</strong>) is a <a href="https://en.wikipedia.org/wiki/Non-parametric_statistics" title="Non-parametric statistics">non-parametric</a> <a href="https://en.wikipedia.org/wiki/Supervised_learning" title="Supervised learning">supervised learning</a> method first developed by <a href="https://en.wikipedia.org/wiki/Evelyn_Fix" title="Evelyn Fix">Evelyn Fix</a> and <a href="https://en.wikipedia.org/wiki/Joseph_Lawson_Hodges_Jr." title="Joseph Lawson Hodges Jr.">Joseph Hodges</a> in 1951, and later expanded by <a href="https://en.wikipedia.org/wiki/Thomas_M._Cover" title="Thomas M. Cover">Thomas Cover</a>. It is used for <a href="https://en.wikipedia.org/wiki/Statistical_classification" title="Statistical classification">classification</a> and <a href="https://en.wikipedia.org/wiki/Regression_analysis" title="Regression analysis">regression</a>. In both cases, the input consists of the <em>k</em> closest training examples in a <a href="https://en.wikipedia.org/wiki/Data_set" title="Data set">data set</a>.</p>
<p>The k-nearest neighbor (k-NN) algorithm is a simple, yet powerful, supervised machine learning method used for classification and regression tasks. It is an instance-based, non-parametric learning method that stores the entire training dataset and makes predictions based on the similarity between data points. The underlying principle of the k-NN algorithm is that similar data points (those that are close to each other in multidimensional space) are likely to have similar outcomes or belong to the same class.</p>
<p>Here’s a description of how the k-NN algorithm works:</p>
<ol type="1">
<li>Determine the value of k: The first step is to choose the number of nearest neighbors (k) to consider when making predictions. The value of k is a user-defined hyperparameter and can significantly impact the algorithm’s performance. A small value of k can lead to overfitting, while a large value may result in underfitting.</li>
<li>Compute distance: Calculate the distance between the new data point (query point) and each data point in the training dataset. The most common distance metrics used are Euclidean, Manhattan, and Minkowski distance. The choice of distance metric depends on the problem and the nature of the data.</li>
<li>Find k-nearest neighbors: Identify the k data points in the training dataset that are closest to the query point, based on the chosen distance metric.</li>
<li>Make predictions: Once the k-nearest neighbors are identified, the final step is to make predictions. The prediction for the query point can be made in two ways:
<ol type="a">
<li>For classification, determine the class labels of the k-nearest neighbors and assign the class label with the highest frequency (majority vote) to the query point. In case of a tie, one can choose the class with the smallest average distance to the query point or randomly select one among the tied classes.</li>
<li>For regression tasks, the k-NN algorithm follows a similar process, but instead of majority voting, it calculates the mean (or median) of the target values of the k-nearest neighbors and assigns it as the prediction for the query point.</li>
</ol>
</li>
</ol>
<p>The k-NN algorithm is known for its simplicity, ease of implementation, and ability to handle multi-class problems. However, it has some drawbacks, such as high computational cost (especially for large datasets), sensitivity to the choice of k and distance metric, and poor performance with high-dimensional or noisy data. Scaling and preprocessing the data, as well as using dimensionality reduction techniques, can help mitigate some of these issues.</p>
<ul>
<li><p>In <em>k-NN classification</em>, the output is a class membership. An object is classified by a plurality vote of its neighbors, with the object being assigned to the class most common among its <em>k</em> nearest neighbors (<em>k</em> is a positive <a href="https://en.wikipedia.org/wiki/Integer" title="Integer">integer</a>, typically small). If <em>k</em>&nbsp;=&nbsp;1, then the object is simply assigned to the class of that single nearest neighbor.</p></li>
<li><p>In <em>k-NN regression</em>, the output is the property value for the object. This value is the average of the values of <em>k</em> nearest neighbors.</p></li>
</ul>
<p><em>k</em>-NN is a type of <a href="https://en.wikipedia.org/wiki/Classification" title="Classification">classification</a> where the function is only approximated locally and all computation is deferred until function evaluation. Since this algorithm relies on distance for classification, if the features represent different physical units or come in vastly different scales then <a href="https://en.wikipedia.org/wiki/Normalization_(statistics)%20%22Normalization%20(statistics)%22">normalizing</a> the training data can improve its accuracy dramatically.</p>
<p>Both for classification and regression, a useful technique can be to assign weights to the contributions of the neighbors, so that the nearer neighbors contribute more to the average than the more distant ones. For example, a common weighting scheme consists in giving each neighbor a weight of 1/<em>d</em>, where <em>d</em> is the distance to the neighbor.</p>
<p>The neighbors are taken from a set of objects for which the class (for <em>k</em>-NN classification) or the object property value (for <em>k</em>-NN regression) is known. This can be thought of as the training set for the algorithm, though no explicit training step is required.</p>
</section><section id="classification-and-regression-trees-cart" class="level3" data-number="14.3.3"><h3 data-number="14.3.3" class="anchored" data-anchor-id="classification-and-regression-trees-cart">
<span class="header-section-number">14.3.3</span> Classification and Regression Trees (CART)</h3>
<p><a href="https://en.wikipedia.org/wiki/Decision_tree_learning">Decision Tree Learning</a> is supervised learning approach used in statistics, data mining and machine learning. In this formalism, a classification or regression decision tree is used as a predictive model to draw conclusions about a set of observations. Decision trees are a popular machine learning method used for both classification and regression tasks. They are hierarchical, tree-like structures that model the relationship between features and the target variable by recursively splitting the data into subsets based on the feature values. Each internal node in the tree represents a decision or test on a feature, and each branch represents the outcome of that test. The leaf nodes contain the final prediction, which is the majority class for classification tasks or the mean/median of the target values for regression tasks.</p>
<p>Here’s an overview of the decision tree learning process:</p>
<ul>
<li>Select the best feature and split value: Start at the root node and choose the feature and split value that results in the maximum reduction of impurity (or increase in information gain) in the child nodes. For classification tasks, impurity measures like Gini index or entropy are commonly used, while for regression tasks, mean squared error (MSE) or mean absolute error (MAE) can be used.</li>
<li>Split the data: Partition the dataset into subsets based on the chosen feature and split value.</li>
<li>Recursion: Repeat steps 1 and 2 for each subset until a stopping criterion is met. Stopping criteria can include reaching a maximum tree depth, a minimum number of samples per leaf, or no further improvement in impurity.</li>
<li>Prune the tree (optional): To reduce overfitting, decision trees can be pruned by removing branches that do not significantly improve the model’s performance on the validation dataset. This can be done using techniques like reduced error pruning or cost-complexity pruning.</li>
</ul>
<p>Decision trees have several advantages, such as:</p>
<ul>
<li><dl>
<dt>Interpretability</dt>
<dd>
They are easy to understand, visualize, and explain, even for non-experts.
</dd>
</dl></li>
<li><dl>
<dt>Minimal data preprocessing</dt>
<dd>
Decision trees can handle both numerical and categorical data, and they are robust to outliers and missing values.
</dd>
</dl></li>
<li><dl>
<dt>Non-linear relationships</dt>
<dd>
They can capture complex non-linear relationships between features and the target variable.
</dd>
</dl></li>
</ul>
<p>However, decision trees also have some drawbacks:</p>
<ul>
<li><dl>
<dt>Overfitting</dt>
<dd>
They are prone to overfitting, especially when the tree is deep or has few samples per leaf. Pruning and setting stopping criteria can help mitigate this issue.
</dd>
</dl></li>
<li><dl>
<dt>Instability</dt>
<dd>
Small changes in the data can lead to different tree structures. This can be addressed by using ensemble methods like random forests or gradient boosting machines (GBMs).
</dd>
</dl></li>
<li><dl>
<dt>Greedy learning</dt>
<dd>
Decision tree algorithms use a greedy approach, meaning they make locally optimal choices at each node. This may not always result in a globally optimal tree.
</dd>
</dl></li>
</ul>
<p>Despite these limitations, decision trees are widely used in various applications due to their simplicity, interpretability, and ability to handle diverse data types.</p>
</section><section id="randomforest" class="level3 page-columns page-full" data-number="14.3.4"><h3 data-number="14.3.4" class="anchored" data-anchor-id="randomforest">
<span class="header-section-number">14.3.4</span> RandomForest</h3>
<p><strong>Random forests</strong> or <strong>random decision forests</strong> is an <a href="https://en.wikipedia.org/wiki/Ensemble_learning" title="Ensemble learning">ensemble learning</a> method for <a href="https://en.wikipedia.org/wiki/Statistical_classification" title="Statistical classification">classification</a>, <a href="https://en.wikipedia.org/wiki/Regression_analysis" title="Regression analysis">regression</a> and other tasks that operates by constructing a multitude of <a href="https://en.wikipedia.org/wiki/Decision_tree_learning" title="Decision tree learning">decision trees</a> at training time. For classification tasks, the output of the random forest is the class selected by most trees. For regression tasks, the mean or average prediction of the individual trees is returned. Random decision forests correct for decision trees’ habit of <a href="https://en.wikipedia.org/wiki/Overfitting" title="Overfitting">overfitting</a> to their <a href="https://en.wikipedia.org/wiki/Test_set" title="Test set">training set</a>. Random forests generally outperform <a href="https://en.wikipedia.org/wiki/Decision_tree_learning" title="Decision tree learning">decision trees</a>, but their accuracy is lower than gradient boosted trees[<em><a href="https://en.wikipedia.org/wiki/Wikipedia:Citation_needed" title="Wikipedia:Citation needed">citation needed</a></em>]. However, data characteristics can affect their performance.</p>
<p>The first algorithm for random decision forests was created in 1995 by <a href="https://en.wikipedia.org/wiki/Tin_Kam_Ho" title="Tin Kam Ho">Tin Kam Ho</a> using the <a href="https://en.wikipedia.org/wiki/Random_subspace_method" title="Random subspace method">random subspace method</a>, which, in Ho’s formulation, is a way to implement the “stochastic discrimination” approach to classification proposed by Eugene Kleinberg.</p>
<p>An extension of the algorithm was developed by <a href="https://en.wikipedia.org/wiki/Leo_Breiman" title="Leo Breiman">Leo Breiman</a> and <a href="https://en.wikipedia.org/wiki/Adele_Cutler" title="Adele Cutler">Adele Cutler</a>, who registered “Random Forests” as a <a href="https://en.wikipedia.org/wiki/Trademark" title="Trademark">trademark</a> in 2006 (as of 2019<a href="https://en.wikipedia.org/w/index.php?title=Random_forest&amp;action=edit">[update]</a>, owned by <a href="https://en.wikipedia.org/wiki/Minitab" title="Minitab">Minitab, Inc.</a>). The extension combines Breiman’s “<a href="https://en.wikipedia.org/wiki/Bootstrap_aggregating" title="Bootstrap aggregating">bagging</a>” idea and random selection of features, introduced first by Ho and later independently by Amit and <a href="https://en.wikipedia.org/wiki/Donald_Geman" title="Donald Geman">Geman</a> in order to construct a collection of decision trees with controlled variance.</p>
<p>Random forests are frequently used as “blackbox” models in businesses, as they generate reasonable predictions across a wide range of data while requiring little configuration.</p>
<div class="cell page-columns page-full">
<div class="cell-output-display page-columns page-full">
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full"><p><img src="images/Random_forest_diagram_complete.png" class="img-fluid figure-img" width="296"></p>
<figcaption class="figure-caption margin-caption"><strong>Figure</strong>. Random forests or random decision forests is an ensemble learning method for classification, regression and other tasks that operates by constructing a multitude of decision trees at training time.</figcaption></figure>
</div>
</div>
</div>
</section></section><section id="practical-machine-learning-with-r-and-mlr3" class="level2 page-columns page-full" data-number="14.4"><h2 data-number="14.4" class="anchored" data-anchor-id="practical-machine-learning-with-r-and-mlr3">
<span class="header-section-number">14.4</span> Practical Machine Learning with R and mlr3</h2>
<p>The mlr3 R package is a modern, object-oriented machine learning framework in R that builds on the success of its predecessor, the mlr package. It provides a flexible and extensible platform for handling common machine learning tasks such as data preprocessing, model training, hyperparameter tuning, and model evaluation <a href="#fig-mlr3-ecosystem">Figure&nbsp;<span>14.3</span></a>. The package is designed to simplify the process of creating and deploying complex machine learning pipelines.</p>
<div class="cell page-columns page-full">
<div class="cell-output-display page-columns page-full">
<div id="fig-mlr3-ecosystem" class="quarto-figure quarto-figure-center anchored page-columns page-full">
<figure class="figure page-columns page-full"><p><img src="images/mlr3_ecosystem.svg" class="img-fluid figure-img"></p>
<figcaption class="figure-caption margin-caption">Figure&nbsp;14.3: The mlr3 ecosystem.</figcaption></figure>
</div>
</div>
</div>
<section id="key-features-of-mlr3" class="level3 page-columns page-full" data-number="14.4.1"><h3 data-number="14.4.1" class="anchored" data-anchor-id="key-features-of-mlr3">
<span class="header-section-number">14.4.1</span> Key features of mlr3</h3>
<ul>
<li><dl>
<dt>Task abstraction</dt>
<dd>
mlr3 encapsulates different types of learning problems like classification, regression, and survival analysis into “Task” objects, making it easier to handle various learning scenarios.
</dd>
</dl></li>
<li><dl>
<dt>Modular design</dt>
<dd>
The package follows a modular design, allowing users to quickly swap out different components such as learners (algorithms), measures (performance metrics), and resampling strategies.
</dd>
</dl></li>
<li><dl>
<dt>Extensibility</dt>
<dd>
Users can extend the functionality of mlr3 by adding custom components like learners, measures, and preprocessing steps via the R6 object-oriented system.
</dd>
</dl></li>
<li><dl>
<dt>Preprocessing</dt>
<dd>
mlr3 provides a flexible way to preprocess data using “PipeOps” (pipeline operations), allowing users to create reusable preprocessing pipelines.
</dd>
</dl></li>
<li><dl>
<dt>Tuning and model selection</dt>
<dd>
mlr3 supports hyperparameter tuning and model selection using various search strategies like grid search, random search, and Bayesian optimization.
</dd>
</dl></li>
<li><dl>
<dt>Parallelization</dt>
<dd>
The package allows for parallelization of model training and evaluation, making it suitable for large-scale machine learning tasks.
</dd>
</dl></li>
<li><dl>
<dt>Benchmarking</dt>
<dd>
mlr3 facilitates benchmarking of multiple algorithms on multiple tasks, simplifying the process of comparing and selecting the best models.
</dd>
</dl></li>
</ul>
<div class="page-columns page-full"><p>You can find more information, including tutorials and examples, on the official mlr3 GitHub repository<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> and the mlr3 book<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>.</p><div class="no-row-height column-margin column-container"><li id="fn1"><p><sup>1</sup>&nbsp;<a href="https://github.com/mlr-org/mlr3" class="uri">https://github.com/mlr-org/mlr3</a></p></li><li id="fn2"><p><sup>2</sup>&nbsp;<a href="https://mlr3book.mlr-org.com/" class="uri">https://mlr3book.mlr-org.com/</a></p></li></div></div>


<div id="refs" class="references csl-bib-body hanging-indent" role="list" style="display: none">
<div id="ref-greener_guide_2022" class="csl-entry" role="listitem">
Greener, Joe G., Shaun M. Kandathil, Lewis Moffat, and David T. Jones. 2022. <span>“A Guide to Machine Learning for Biologists.”</span> <em>Nature Reviews Molecular Cell Biology</em> 23 (1): 40–55. <a href="https://doi.org/10.1038/s41580-021-00407-0">https://doi.org/10.1038/s41580-021-00407-0</a>.
</div>
<div id="ref-libbrecht_machine_2015" class="csl-entry" role="listitem">
Libbrecht, Maxwell W., and William Stafford Noble. 2015. <span>“Machine Learning Applications in Genetics and Genomics.”</span> <em>Nature Reviews Genetics</em> 16 (6): 321–32. <a href="https://doi.org/10.1038/nrg3920">https://doi.org/10.1038/nrg3920</a>.
</div>
</div>
</section></section></main><!-- /main --><script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script><nav class="page-navigation"><div class="nav-page nav-page-previous">
      <a href="./kmeans.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">K-means clustering</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./geoquery.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Accessing and working with public omics data</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer"><div class="nav-footer">
    <div class="nav-footer-left">
      &nbsp;
    </div>   
    <div class="nav-footer-center">
      <ul class="footer-items list-unstyled">
<li class="nav-item">
    <a class="nav-link" href="./license.html">License</a>
  </li>  
</ul>
</div>
    <div class="nav-footer-right">
      &nbsp;
    </div>
  </div>
</footer>


<script src="site_libs/quarto-html/zenscroll-min.js"></script>
</body></html>